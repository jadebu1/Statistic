---
title: "Homework 5"
author: "Jade Butler"
date: "`r Sys.Date()`"
output: openintro::lab_report
---

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(infer)
```

### Problem 1

If we randomly select two 5lb bags of potatoes and one 10lb bag of potatoes, what is the probability that the sum of the weights of the two 5lb bags exceeds the weight for one 10lb bag?

Xi = weight of randomly selected 5lb bag of potatoes, Distribution is as follows Xi~N(5.34,0.13)

Y = weight of randomly selected 10lb bag of potatoes, Distribution is as Y~N(10.25, 0.19)

U = X + X

E(U) = E(X+X) = E(X) + E(X) = 5.34 + 5.34 = 10.68
V(U) = V(X+X) = V(X) + V(X) = 0.19 + 0.19 = 0.38

U~N(10.68,0.38)

V = U - Y

E(V) = E(U) - E(Y) = 10.68 - 10.25 = 0.43

V(V) = V(U) - V(Y) = 0.38 + 0.19 = 0.57

P(U>Y) = P(U-Y>0) = P(V>0)

P(U>Y) = ((V-E(V)/SD(V))>((0-0.43)/sqrt(0.57))

P(U>Y) = P(z>-0.5695)

P(U>Y) = 1 - P(z>-0.5695) = 0.71549

The probability that two randomly selected 5lb bags of potatoes weigh more than one 10lb bag of potatoes is 0.71549.

### Problem 2
#### Read in Data
```{r read in ZOD data}
ZOD <- read_csv("ZODTwoGroups.csv")
ZOD$Pie <- factor(ZOD$Pie)
```

#### Part a)
```{r comparative boxplot}
ggplot(ZOD, aes(x=Pie, y=ZOD)) + geom_boxplot() + xlab("Pie Type") + ylab("ZOD")
```

Comparing the types of pie consumed and their respective ZOD duration boxplots, there seems to be significantly less ZOD duration after Apple Pie is consumed compared to when Cherry Pie is consumed.

#### Part b)
```{r create permutations}
set.seed(12)
PermsOut <- ZOD %>% 
   rep_sample_n(size = nrow(ZOD), reps = 1000, replace = FALSE) %>% 
   mutate(ZOD_perm = sample(ZOD)) %>%
   group_by(replicate, Pie) %>% 
   summarize(prop_ZOD_perm = mean(ZOD_perm), prop_ZOD = mean(ZOD)) %>% 
   summarize(diff_perm = diff(prop_ZOD_perm), diff_orig = diff(prop_ZOD)) 

PermsOut

```

The observed difference for the statistical data is 3.67.

#### Part c)
The statistical hypotheses are the average of Apple Pie's population is considered to be less than the average of the Cherry Pie's population. In other words, the average of the Cherry Pie's population is larger than the Apple Pie's population with the difference being large enough to be statistically significant.

#### Part d)
```{r Histogram of Null Distribution}
origdiff <- PermsOut$diff_orig[1]
yheight <- max(table(PermsOut$diff_perm))
h1 <- ggplot(data = PermsOut, aes(x = diff_perm)) +
  geom_histogram(bins = 13, colour = 1, fill = "white") + xlab("") + geom_vline(xintercept = origdiff, col="Red")
h1
```

The overall spread of the sample is unimodal and pretty symmetric, and although the observed sample is rare, it is where we expected it to be around 3.65. I think this observed difference is fairly skewed because of how different the two population groups are.

#### Part e)
```{r p-value}
PermsOut %>% 
  summarize(count = sum(diff_orig >= diff_perm),
            proportion = mean(diff_orig <= diff_perm))
```

This P-value implies there is a significant difference between Apple Pie and Cherry Pie which is consistent with our hypothesis and with what we found within the sample and sample difference.


#### Part f)

From the hypothesis test allowed me to come to the conclusion that there is a large differences between the ZOD duration of the Apple Pie and the Cherry Pie population. Overall the mean for ZOD duration of Cherry Pie is 3.67 greater than the ZOD duration of Apple Pie as found by the observed difference for the statistical data is 3.67.

### Problem 3
#### Part a)
```{r read in wt loss data}
WL <- read_csv("PopularDietsCombined.csv")
WL$Diet <- factor(WL$Diet)
ggplot(WL, aes(x=Diet, y=WtLossKG)) + geom_boxplot() + xlab("Diet Type") + ylab("Weight Loss KG")
```
#### Part b)
```{r find mean wt loss}
mean(WL$WtLossKG) 

```


#### Part c)
```{r bootstrap samples}
# code for bootstrap samples given; need to add code for histogram
set.seed(12)
# 1000 bootstrap samples so we can display the distribution
n <- 93 
samp <- WL %>% sample_n(size = n)
BootSamp1000A <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean")

BootSamp1000A

B1 <- ggplot(data = BootSamp1000A, aes(x = stat )) +
  geom_histogram(bins = 10, colour = 1, fill = "white") +
  xlab("phat")

B1
```


#### Part d)
```{r get 95 percent CI}
set.seed(12)
n <- 93 
samp <- WL %>% sample_n(size = n)
(BootSamp1000B <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95))
```


#### Part e)
```{r get 90 and 99 percent CI}
#We want to you repeat set.seed for both sets of samples
set.seed(12)
n <- 93 
samp <- WL %>% sample_n(size = n)
(BootSamp1000C <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.90))

 
set.seed(12)
(BootSamp1000D <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.99))



```


#### Part f)

I think the new intervals will be minimal percentages larger than they were in part D.


``` {r bootstrap 1000 samples with 95ci}
n <- 93 
samp <- WL %>% sample_n(size = n)
(BootSamp1000E <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95))
```



#### Part g)
```{r bootstrap samples new}
# no set.seed in this part
n <- 93 
samp <- WL %>% sample_n(size = n)
(BootSamp1000F <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95))
 
(BootSamp1000G <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95))

```


Yes they do support what I wrote for part F, the first 1000 samples I drew had a lower bound of 3.542 and an upper bound of 6.336. The second set of samples I drew had a lower bound of 3.575 and an upper bound of 6.285

#### Part h)

I think the intervals would change by a larger number than when the confidence interval was set for 95 becuase of the smaller sample size.

#### Part i)
```{r smaller bootstrap samples}
set.seed(12)
# code provided for n=500; add code for n=100 and n=10
# 500 bootstrap samples
WL %>%  specify(response = WtLossKG) %>% 
  generate(reps = 500, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95)

n <- 100 
samp <- WL %>% sample_n(size = n, replace = TRUE )  
set.seed(12) 
(BootSamp1000H <- samp %>% specify(response = WtLossKG) %>% 
  generate(reps = 500, type = "bootstrap") %>% 
  calculate(stat = "mean") %>% 
  get_ci(level = 0.95))

n <- 10 
samp <- WL %>% sample_n(size = n)
set.seed(12)  
(BootSamp1000F <- samp %>%  specify(response = WtLossKG) %>% 
  generate(reps = 500, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = 0.95))

```


Yes these 95% confidence intervals do support what I wrote for part H. The first sample I took where n=500 had a very similar interval to that of the 1000 samples interval, the upper bound for this set was 6.2378 and the lower bound was 3.581. For the second set with 500 samples drawn from 100 (with replacement), had larger changes in it's upper/lower bounds than I have seen thus far with the upper bound = 6.883 and the Lower bound = 4.219. The final sample set with 500 samples out of 10 had a vastly different lower bound at 0.4965 and an upper bound at 7.10.


...

fix incorrect commit comment

